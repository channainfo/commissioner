# SpreeCmCommissioner

![Commission gem build status](https://github.com/channainfo/commissioner/actions/workflows/publish.yml/badge.svg?branch= "Build status")

An application platform built on top of Spree commerce for modeling any bussiness applications.

## Installation

1; Add this extension to your Gemfile with this line:

```ruby
gem 'spree_cm_commissioner'
```

2; Install the gem using Bundler

```ruby
bundle install
```

3; Copy & run migrations

```ruby
bundle exec rails g spree_cm_commissioner:install
```

4; Restart your server

If your server was running, restart it so that it can find the assets properly.

## Config

### Rake tasks

```sh
# Seed province data for Cambodia country
rake data:seed_kh_provinces

# Seed option values and type location
rake data:seed_kh_location_option_values

# Reindex Elasticsearch on Vendor model
rake searchkick:reindex CLASS=Spree::Vendor
```

### Google Map

CM commissioner required Google Map key for [map components](app/views/shared/map/_map.html.erb).

```env
# .env
GOOGLE_MAP_KEY = ""
DEFAULT_LATLON = "10.627543,103.522141"
```

<!-- * Describe new config usage above -->
<!-- * Also put in summary at the last section [All environments] below -->

### Elasticsearch

Commissioner required elasticsearch version 8.5.2. We recommend using [evm](https://github.com/duydo/evm) to manage their version.

1, Install EVM (Elasticsearch Version Manager):

```sh
sudo curl -o /usr/local/bin/evm https://raw.githubusercontent.com/duydo/evm/master/evm
sudo chmod +x /usr/local/bin/evm
```

2, Install elasticsearch

```sh
evm install 8.5.2

# To start elasticsearch
evm start

# To stop elasticsearch
evm stop
```

### Visual Studio Code Editor && Rubocop

- Install VScode Extensions: **ruby-rubocop**

- Make sure have below settings in VScode User Settings. It will auto-correct with rubocop after save file

```json
{
  "ruby.rubocop.executePath": "/Users/USER_NAME/.rbenv/shims/"
}
```

- We can run auto correction

```sh
#  Autocorrect offenses (only when it's safe)
$ bundle exec rubocop -a # or bundle exec rubocop --auto-correct

# Autocorrect offenses (safe and unsafe).
$ bundle exec rubocop -A # or bundle exec rubocop --auto-correct-all
```

### All environments

Following are required varialbles inside .env

```env
GOOGLE_MAP_KEY = ""
DEFAULT_LATLON = "10.627543,103.522141"
ACCOMMODATION_MAX_STAY_DAYS = 10
DEFAULT_TELEGRAM_BOT_API_TOKEN = ""

PIN_CODE_DEBUG_NOTIFIY_TELEGRAM_ENABLE="yes"
RECAPTCHA_TOKEN_VALIDATOR_ENABLE="yes"

EXCEPTION_NOTIFY_ENABLE="yes" # yes or no
EXCEPTION_TELEGRAM_BOT_TOKEN=""
EXCEPTION_NOTIFIER_TELEGRAM_CHANNEL_ID=""
```

## Using Deface DSL (.deface files)

- Make sure the path of override should match the path of view template
- The .deface can be use with :erb, :html, or :text

Example:

```sh
View Template file: app/views/spree/admin/vendors/_form
Override file: app/overrides/spree/admin/vendors/_form/logo.html.erb.deface
```

<https://github.com/spree/deface#using-the-deface-dsl-deface-files>

## Schedule Jobs

- Create a schedule to update vendor min and max price
- Frequently: every 24 hours
- Run time: mid night is preferable
- Command: `rake "spree_cm_commissioner:vendor_update_price_range"`
- Customer_notification

````yml
customer_notification:
  cron: '0 0 * * * *'   # will trigger every hour, every day of the month, every month, and every day of the week
  class: SpreeCmCommissioner::CustomerNotificationCron
````

## Testing

First bundle your dependencies, then run `rake`. `rake` will default to building the dummy app if it does not exist, then it will run specs. The dummy app can be regenerated by using `rake test_app`.

```sh
bundle update
bundle exec rake test_app
```

When testing your applications integration with this extension you may use it's factories.
Simply add this require statement to your spec_helper:

```ruby
require 'spree_cm_commissioner/factories'
```

### Run test with Github action

We are utilizing GitHub Actions workflows defined in .github/workflows/publish.yml.

### Run test with docker

Our project includes both a Dockerfile and a docker-compose.yml configuration. If you require more fine-grained control over your workflow, including environment setup and database services, use docker-compose to build the images and run them in one go. However, you can also configure docker-compose to run tests with your external database installation.

> **Note**: By default, we use a local instance of PostgreSQL.

To manually build and run the Docker image with an external database:

```sh
> docker build -t central-market-comissioner_web .
> docker run -e DATABASE_URL=postgres://postgres:@192.168.1.136:5432/spree_cm_commissioner_spree_test -e RAILS_ENV=test -it central-market-comissioner_web bash
> bundle exec rake
```

To build and run the project with docker-compose:

```sh
docker-compose build
docker-compose up --build
```

This setup allows you to configure the environment and database services in a single step, making it easier to manage and run tests.

## Releasing

```sh
bundle exec gem bump -p -t
bundle exec gem release
```

For more options please see [gem-release REAMDE](https://github.com/svenfuchs/gem-release)

## Troubleshooting Database Lock on Taxonomy Creation Errors
### Issue Overview
In development, this error can occur after creating a new database and restoring the database (e.g., from a staging environment). When this happens, attempts to create a new Taxonomy may fail due to a record lock.

### Error Message
In case you create in console manualy
```
/usr/local/bundle/gems/activerecord-7.0.8/lib/active_record/locking/pessimistic.rb:70:in `lock!': Locking a record with unpersisted changes is not supported. Use `save` to persist the changes, or `reload` to discard them explicitly. (RuntimeError)
```
In case you create from web-app
```
Locking a record with unpersisted changes is not supported. Use save to persist the changes, or reload to discard them explicitly.

Extracted source (around line #70):

if persisted?
  if has_changes_to_save?
    raise(<<-MSG.squish)
      Locking a record with unpersisted changes is not supported. Use
      `save` to persist the changes, or `reload` to discard them
      explicitly.
```

### Workaround Solution
1.  Open the Rails console: `rails console`
2. Find an existing Taxonomy record: `taxonomy = Spree::Taxonomy.last`
3. Update any attribute to release the lock. For example: `taxonomy.update(name: "#{taxonomy.name}1")`

This action should unlock the record, allowing you to successfully create a new Taxonomy.


## Contributing

If you'd like to contribute, please take a look at the
[instructions](CONTRIBUTING.md) for installing dependencies and crafting a good
pull request.

Copyright (c) 2022 [name of extension creator], released under the New BSD License

### Account Deletion Cron Job

- **AccountDeletionCronJob**
- Frequently: every 24 hours
- Deleted Account will last for 1 month before it is permanently deleted

### Multiple databases

In most cases, Rails is able to infer the database connection. However in some instances, for example, in the spree_backend gem, it uses the GET request
to destroy the session which in turn triggers database update that require the writing role. To fix this we need to explicitly tell Rails to use the right database connection.

Error using a wrong database connection looks like this:

```rb
raise ActiveRecord::ReadOnlyError, "Write query attempted while in readonly mode: #{sql}"
```

An ActiveRecord::ReadOnlyError occurred in orders#new.

```ruby
module SpreeCmCommissioner
  module Admin
    module UserSessionsControllerDecorator
      def self.prepended(base)
        # spree_devise_auth gem use get as destroy
        # get '/logout' => 'user_sessions#destroy', :as => :logout
        base.around_action :set_writing_role, only: %i[destroy]
      end
    end
  end
end

unless Spree::Admin::UserSessionsController.ancestors.include?(SpreeCmCommissioner::Admin::UserSessionsControllerDecorator)
  Spree::Admin::UserSessionsController.prepend(SpreeCmCommissioner::Admin::UserSessionsControllerDecorator)
end

```

## Avoid Excessive Looping

This test ensures that the query for fetching events does not loop excessively for each item.

### Test Explanation

The test is structured as follows:

1. **Capture Rails Logger**: It captures the Rails logger to inspect logs generated during the test execution.
2. **Execute the Query**: It executes the query to fetch events.
3. **Expectation 1**: It expects the query execution to complete without raising any errors.
4. **Expectation 2**: It checks the captured Rails logs for any indication of excessive looping. This is done by verifying that the log messages do not include the phrase "Loop detected".
5. **Restore Original Rails Logger**: Finally, it restores the original Rails logger.

### Test Code (Ruby RSpec)

```ruby
it 'should not loop excessively for each item' do
  # Capture the Rails logger to inspect logs
  logs = StringIO.new
  Rails.logger = Logger.new(logs)

  # Execute the query
  query = SpreeCmCommissioner::DashboardCrewEventQuery.new(user_id: user_a.id, section: 'incoming')

  # Expectation: The query should complete without raising any errors
  expect { query.events }.not_to raise_error

  # Expectation: Check Rails logs for excessive looping
  expect(logs.string).not_to include('Loop detected')  # Adjust this log message according to your implementation

  # Restore the original Rails logger
  Rails.logger = ActiveSupport::Logger.new(STDOUT)
end

```

## Protected Cloudfront with signed requests

To use signed cookies with CloudFront, you'll need to set up your CloudFront distribution to require signed cookies and then generate and distribute the signed cookies to your users. Hereâ€™s how to do it using Terraform for infrastructure setup and Ruby for cookie generation.

### Generating keypair

Generate private key

```sh
openssl genrsa -out private_key.pem 2048
```

Use the private_key.pem to generate the public key

```sh
openssl rsa -pubout -in private_key.pem -out public_key.pem
```

### Using the keypair i Cloudfront

Currently this process can not be done directly with terraform due to the fact that Cloudfront use a global region and our Terraform script works with infrastructures in a specific region.

1. Go to Cloudfront -> Select Key management and then add a key using your public key
2. On the left navigation menu -> Select Keypair with the public key create in the step 1.
3. Copy the id of the key pair

### Using signed cookie in from Cloudfront

You can send the cookies generated byt the SignedCookies

```dart
Future<void> _initializePlayer() async {
  final client = http.Client();
  final uri = Uri.parse(widget.url);
  final request = http.Request('GET', uri)
    ..headers.addAll({
      'Cookie': widget.cookies.entries
          .map((entry) => '${entry.key}=${entry.value}')
          .join('; ')
    });

  final response = await client.send(request);

  if (response.statusCode == 200) {
    _videoPlayerController = VideoPlayerController.network(widget.url);
    await _videoPlayerController.initialize();
    _chewieController = ChewieController(
      videoPlayerController: _videoPlayerController,
      aspectRatio: _videoPlayerController.value.aspectRatio,
      autoPlay: true,
      looping: true,
    );
    setState(() {});
  } else {
    // Handle error
    print('Error loading video');
  }
}

```

where the cookies is a

```dart
final Map<String, String> cookies;
```

## References

### Adaptive bitrate player

- <https://livepush.io/hls-player/index.html>
